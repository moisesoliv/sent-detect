{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "get_twitter_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "environment": {
      "name": "common-cpu.m46",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m46"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moisesoliv/sent-detect/blob/master/get_twitter_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UFRQcDfnmGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "cb351d77-c2c4-4ee6-e5af-757fdb00a6fa"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/tcc')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-20T13:48:17.301584Z",
          "start_time": "2020-06-20T13:48:14.271140Z"
        },
        "colab_type": "code",
        "id": "DME6l6elv6HA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b1aca8bd-16d5-46e4-d549-a57c8ad62f92"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "from modules.preprocessing import *"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-20T13:48:17.317316Z",
          "start_time": "2020-06-20T13:48:17.304669Z"
        },
        "colab_type": "code",
        "id": "n2t9nI9pvMI8",
        "colab": {}
      },
      "source": [
        "class EmotionDetect:\n",
        "    def __init__(self, vectors_name, w_folder):\n",
        "        self.w_folder = w_folder\n",
        "        self.size_word2vec = 300\n",
        "        self.max_sequences = 35\n",
        "        # self.vectors = pickle.load(open('w2v_stop'+str(self.size_word2vec)+'.pkl', 'rb'))\n",
        "        self.vectors = pickle.load(open(vectors_name, \"rb\"))\n",
        "        self.emotions = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
        "        self.tokenizer = Tokenizer()\n",
        "        self.loadModels()\n",
        "\n",
        "    def model_gru(self, embedding_matrix, embed_size):\n",
        "        # load json and create model\n",
        "        json_file = open(\"models/bi-gru300.json\", \"r\")\n",
        "        loaded_model_json = json_file.read()\n",
        "        json_file.close()\n",
        "        return tf.keras.models.model_from_json(loaded_model_json)\n",
        "\n",
        "    def loadModels(self):\n",
        "        self.models = dict()\n",
        "        for s in self.emotions:\n",
        "            self.models[s] = self.model_gru(self.vectors.wv.vectors, self.size_word2vec)\n",
        "            self.models[s].load_weights(\"models/\" + s + \"_weights.h5\")\n",
        "\n",
        "    def getIndex(self, t):\n",
        "        try:\n",
        "            return self.vectors.wv.vocab[t].index\n",
        "\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "    def predict(self, text):\n",
        "        x = self.tokenizer.cleanText(text)\n",
        "        x = [self.getIndex(t) for t in x]\n",
        "        x = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "            [x], maxlen=self.max_sequences\n",
        "        )\n",
        "        return dict(\n",
        "            zip(self.emotions, [self.models[s].predict(x)[0][0] for s in self.emotions])\n",
        "        )"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-20T13:48:17.334706Z",
          "start_time": "2020-06-20T13:48:17.320032Z"
        },
        "colab_type": "code",
        "id": "Bsm0Tyn536kd",
        "colab": {}
      },
      "source": [
        "# classifier = EmotionDetect('models/ft_300.pkl', 'models')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-20T13:48:21.216739Z",
          "start_time": "2020-06-20T13:48:17.337236Z"
        },
        "colab_type": "code",
        "id": "Dcixu0feflXy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "74e5d77f-79cf-4a32-e7e5-c9951732879d"
      },
      "source": [
        "from datetime import timedelta, date\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from random import randint\n",
        "from time import sleep\n",
        "\n",
        "!pip install GetOldTweets3 ratelimit\n",
        "import GetOldTweets3 as got\n",
        "from ratelimit import limits, sleep_and_retry\n",
        "\n",
        "def daterange(start_date, end_date):\n",
        "    for n in range(int ((end_date - start_date).days)):\n",
        "        yield start_date + timedelta(n)\n",
        "\n",
        "@sleep_and_retry\n",
        "@limits(calls=12, period=900) # 10 calls in 15 minutes\n",
        "def get_tweets_request(got, tweetCriteria):\n",
        "        return got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "\n",
        "\n",
        "def get_data(word, year=2020, month=1):\n",
        "\n",
        "    start_date = date(year, month, 1)\n",
        "    end_date = date(year, month, 1) + relativedelta(months=1)\n",
        "\n",
        "    tweets = []\n",
        "    for single_date in tqdm(daterange(start_date, end_date), total=(end_date - start_date).days):\n",
        "        # print(single_date)\n",
        "        day = single_date.strftime(\"%Y-%m-%d\")\n",
        "        dayPlus = (single_date + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        tweetCriteria = got.manager.TweetCriteria()\\\n",
        "                                            .setQuerySearch(word)\\\n",
        "                                            .setSince(day)\\\n",
        "                                            .setUntil(dayPlus)\\\n",
        "                                            .setLang('en')\\\n",
        "                                            .setTopTweets(True)\\\n",
        "                                            .setMaxTweets(1000)\n",
        "        tweet = get_tweets_request(got, tweetCriteria) # got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "\n",
        "        for t in (tweet):\n",
        "            # emo = classifier.predict(t.text)\n",
        "            tweets.append({\n",
        "                        'date': t.date,\n",
        "                        'id': t.id,\n",
        "                        'username': t.username,\n",
        "                        'text': t.text,\n",
        "                        'favorites': t.favorites,\n",
        "                        'retweets': t.retweets,\n",
        "                        'replies': t.replies,\n",
        "                        'geo': t.geo\n",
        "                        # 'anger' : int(emo['anger'] > 0.22),\n",
        "                        # 'disgust' : int(emo['disgust'] > 0.1),\n",
        "                        # 'fear': int(emo['fear'] > 0.1),\n",
        "                        # 'joy' : int(emo['joy'] > 0.1),\n",
        "                        # 'sadness' : int(emo['sadness'] > 0.1),\n",
        "                        # 'surprise': int(emo['surprise'] > 0.13),\n",
        "\n",
        "                        # 'anger_pred': emo['anger'],\n",
        "                        # 'disgust_pred' : emo['disgust'],\n",
        "                        # 'fear_pred': emo['fear'],\n",
        "                        # 'joy_pred': emo['joy'],\n",
        "                        # 'sadness_pred': emo['sadness'],\n",
        "                        # 'surprise_pred': emo['surprise']\n",
        "                        })\n",
        "        aux = pd.DataFrame(tweets)\n",
        "        aux.to_csv('data/data_autosave.csv')\n",
        "        sleep(randint(1,10))\n",
        "    return tweets"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting GetOldTweets3\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/f4/a00c2a7c90801abc875325bb5416ce9090ac86d06a00cc887131bd73ba45/GetOldTweets3-0.0.11-py3-none-any.whl\n",
            "Collecting ratelimit\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/38/ff60c8fc9e002d50d48822cc5095deb8ebbc5f91a6b8fdd9731c87a147c9/ratelimit-2.2.1.tar.gz\n",
            "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (4.2.6)\n",
            "Collecting pyquery>=1.2.10\n",
            "  Downloading https://files.pythonhosted.org/packages/78/43/95d42e386c61cb639d1a0b94f0c0b9f0b7d6b981ad3c043a836c8b5bc68b/pyquery-1.4.1-py2.py3-none-any.whl\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: ratelimit\n",
            "  Building wheel for ratelimit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ratelimit: filename=ratelimit-2.2.1-cp36-none-any.whl size=5893 sha256=5f80bcf7e8741917226f09009349d25a2e3fba6fbd0c29704d95699408eb79ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/d9/82/3c6044cf1a54aab9151612458446d9b17a38416869e1b1d9b8\n",
            "Successfully built ratelimit\n",
            "Installing collected packages: cssselect, pyquery, GetOldTweets3, ratelimit\n",
            "Successfully installed GetOldTweets3-0.0.11 cssselect-1.1.0 pyquery-1.4.1 ratelimit-2.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-20T13:48:21.225927Z",
          "start_time": "2020-06-20T13:48:21.219795Z"
        },
        "colab_type": "code",
        "id": "vH36ZZDbhl1n",
        "colab": {}
      },
      "source": [
        "def get_plot(search, start_m=1, start_y=2019, end_m=1, end_y=2020):\n",
        "    for y, m in month_year_iter(start_m, start_y, end_m, end_y):\n",
        "        try:\n",
        "            name = str(y) + str(m)\n",
        "            tweets = get_data(search, year=y, month=m)\n",
        "            df = pd.DataFrame(tweets)\n",
        "            df.to_csv(\"data/tweets_\" + search + \"_\" + name + \".csv\")\n",
        "        except:\n",
        "            print(\"[ERROR]\" + \"data/tweets_\" + search + \"_\" + name)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-20T13:48:15.306Z"
        },
        "id": "mYDafU-okRWj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46afd85a-bf7f-41c6-b32a-ee3f8e0824ad"
      },
      "source": [
        "get_plot('nba', 5, 2019, 7, 2019) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 39%|███▊      | 12/31 [04:36<08:02, 25.38s/it]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}