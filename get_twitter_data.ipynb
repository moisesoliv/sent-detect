{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "get_twitter_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "environment": {
      "name": "common-cpu.m46",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m46"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UFRQcDfnmGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "048d76b2-449c-4216-c444-16b21df8386e"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/tcc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-20T13:48:17.301584Z",
          "start_time": "2020-06-20T13:48:14.271140Z"
        },
        "colab_type": "code",
        "id": "DME6l6elv6HA",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "from modules.preprocessing import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-20T13:48:17.317316Z",
          "start_time": "2020-06-20T13:48:17.304669Z"
        },
        "colab_type": "code",
        "id": "n2t9nI9pvMI8",
        "colab": {}
      },
      "source": [
        "class EmotionDetect:\n",
        "    def __init__(self, vectors_name, w_folder):\n",
        "        self.w_folder = w_folder\n",
        "        self.size_word2vec = 300\n",
        "        self.max_sequences = 35\n",
        "        # self.vectors = pickle.load(open('w2v_stop'+str(self.size_word2vec)+'.pkl', 'rb'))\n",
        "        self.vectors = pickle.load(open(vectors_name, \"rb\"))\n",
        "        self.emotions = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
        "        self.tokenizer = Tokenizer()\n",
        "        self.loadModels()\n",
        "\n",
        "    def model_gru(self, embedding_matrix, embed_size):\n",
        "        # load json and create model\n",
        "        json_file = open(\"models/bi-gru300.json\", \"r\")\n",
        "        loaded_model_json = json_file.read()\n",
        "        json_file.close()\n",
        "        return tf.keras.models.model_from_json(loaded_model_json)\n",
        "\n",
        "    def loadModels(self):\n",
        "        self.models = dict()\n",
        "        for s in self.emotions:\n",
        "            self.models[s] = self.model_gru(self.vectors.wv.vectors, self.size_word2vec)\n",
        "            self.models[s].load_weights(\"models/\" + s + \"_weights.h5\")\n",
        "\n",
        "    def getIndex(self, t):\n",
        "        try:\n",
        "            return self.vectors.wv.vocab[t].index\n",
        "\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "    def predict(self, text):\n",
        "        x = self.tokenizer.cleanText(text)\n",
        "        x = [self.getIndex(t) for t in x]\n",
        "        x = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "            [x], maxlen=self.max_sequences\n",
        "        )\n",
        "        return dict(\n",
        "            zip(self.emotions, [self.models[s].predict(x)[0][0] for s in self.emotions])\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-20T13:48:17.334706Z",
          "start_time": "2020-06-20T13:48:17.320032Z"
        },
        "colab_type": "code",
        "id": "Bsm0Tyn536kd",
        "colab": {}
      },
      "source": [
        "# classifier = EmotionDetect('models/ft_300.pkl', 'models')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-20T13:48:21.216739Z",
          "start_time": "2020-06-20T13:48:17.337236Z"
        },
        "colab_type": "code",
        "id": "Dcixu0feflXy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c29c50dc-8fe1-4b50-dc2c-9f00ae4b6ef7"
      },
      "source": [
        "from datetime import timedelta, date\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from random import randint\n",
        "from time import sleep\n",
        "\n",
        "!pip install GetOldTweets3 ratelimit\n",
        "import GetOldTweets3 as got\n",
        "from ratelimit import limits, sleep_and_retry\n",
        "\n",
        "def daterange(start_date, end_date):\n",
        "    for n in range(int ((end_date - start_date).days)):\n",
        "        yield start_date + timedelta(n)\n",
        "\n",
        "@sleep_and_retry\n",
        "@limits(calls=12, period=900) # 10 calls in 15 minutes\n",
        "def get_tweets_request(got, tweetCriteria):\n",
        "        return got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "\n",
        "\n",
        "def get_data(word, year=2020, month=1):\n",
        "\n",
        "    start_date = date(year, month, 1)\n",
        "    end_date = date(year, month, 1) + relativedelta(months=1)\n",
        "\n",
        "    tweets = []\n",
        "    for single_date in tqdm(daterange(start_date, end_date), total=(end_date - start_date).days):\n",
        "        # print(single_date)\n",
        "        day = single_date.strftime(\"%Y-%m-%d\")\n",
        "        dayPlus = (single_date + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        tweetCriteria = got.manager.TweetCriteria()\\\n",
        "                                            .setQuerySearch(word)\\\n",
        "                                            .setSince(day)\\\n",
        "                                            .setUntil(dayPlus)\\\n",
        "                                            .setLang('en')\\\n",
        "                                            .setTopTweets(True)\\\n",
        "                                            .setMaxTweets(1000)\n",
        "        tweet = get_tweets_request(got, tweetCriteria) # got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "\n",
        "        for t in (tweet):\n",
        "            # emo = classifier.predict(t.text)\n",
        "            tweets.append({\n",
        "                        'date': t.date,\n",
        "                        'id': t.id,\n",
        "                        'username': t.username,\n",
        "                        'text': t.text,\n",
        "                        'favorites': t.favorites,\n",
        "                        'retweets': t.retweets,\n",
        "                        'replies': t.replies,\n",
        "                        'geo': t.geo\n",
        "                        # 'anger' : int(emo['anger'] > 0.22),\n",
        "                        # 'disgust' : int(emo['disgust'] > 0.1),\n",
        "                        # 'fear': int(emo['fear'] > 0.1),\n",
        "                        # 'joy' : int(emo['joy'] > 0.1),\n",
        "                        # 'sadness' : int(emo['sadness'] > 0.1),\n",
        "                        # 'surprise': int(emo['surprise'] > 0.13),\n",
        "\n",
        "                        # 'anger_pred': emo['anger'],\n",
        "                        # 'disgust_pred' : emo['disgust'],\n",
        "                        # 'fear_pred': emo['fear'],\n",
        "                        # 'joy_pred': emo['joy'],\n",
        "                        # 'sadness_pred': emo['sadness'],\n",
        "                        # 'surprise_pred': emo['surprise']\n",
        "                        })\n",
        "        aux = pd.DataFrame(tweets)\n",
        "        aux.to_csv('data/data_autosave.csv')\n",
        "        sleep(randint(1,10))\n",
        "    return tweets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: GetOldTweets3 in /usr/local/lib/python3.6/dist-packages (0.0.11)\n",
            "Requirement already satisfied: ratelimit in /usr/local/lib/python3.6/dist-packages (2.2.1)\n",
            "Requirement already satisfied: pyquery>=1.2.10 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (1.4.1)\n",
            "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (4.2.6)\n",
            "Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.6/dist-packages (from pyquery>=1.2.10->GetOldTweets3) (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-20T13:48:21.225927Z",
          "start_time": "2020-06-20T13:48:21.219795Z"
        },
        "colab_type": "code",
        "id": "vH36ZZDbhl1n",
        "colab": {}
      },
      "source": [
        "def get_plot(search, start_m=1, start_y=2019, end_m=1, end_y=2020):\n",
        "    for y, m in month_year_iter(start_m, start_y, end_m, end_y):\n",
        "        try:\n",
        "            name = str(y) + str(m)\n",
        "            tweets = get_data(search, year=y, month=m)\n",
        "            df = pd.DataFrame(tweets)\n",
        "            df.to_csv(\"data/tweets_\" + search + \"_\" + name + \".csv\")\n",
        "        except:\n",
        "            print(\"[ERROR]\" + \"data/tweets_\" + search + \"_\" + name)\n",
        "            # continue\n",
        "        # df['date'] = pd.to_datetime(df['date']).dt.normalize()\n",
        "        # result = df.set_index('date')[['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']].resample(\"D\").sum()\n",
        "\n",
        "        # plot = result.plot(figsize=(20,10))\n",
        "        # plot.figure.savefig('figures/sent_'+search+'_'+name+'.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-20T13:48:15.306Z"
        },
        "id": "mYDafU-okRWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get_plot('floyd', 6, 2020, 7, 2020) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em_xeMoPvW0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get_plot('police', 5, 2020, 7, 2020) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RILr7vZrNth3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f7d68fec-7889-4303-e175-269b53bc3163"
      },
      "source": [
        "get_plot('racism', 5, 2020, 7, 2020) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [35:59<00:00, 69.65s/it]\n",
            "100%|██████████| 30/30 [39:55<00:00, 79.87s/it] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmy-VHEi28n7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "55066709-1335-47db-d2da-a2b1832a42c0"
      },
      "source": [
        "get_plot('#america', 7, 2018, 8, 2018)\n",
        "get_plot('#america', 7, 2019, 8, 2019)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [30:24<00:00, 58.84s/it]\n",
            "100%|██████████| 31/31 [44:10<00:00, 85.48s/it] \n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}