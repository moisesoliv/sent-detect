{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27581,
     "status": "ok",
     "timestamp": 1589462877201,
     "user": {
      "displayName": "Moisés Oliveira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi3zXARzg3mEYgGoqoQsflEXnzm_wT1KuBZBsB37A=s64",
      "userId": "12199513049896561840"
     },
     "user_tz": 180
    },
    "id": "veHVXrK3Yg8O",
    "outputId": "990cec7e-bc1e-4138-e260-b51a2f3cb705"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n\\nimport os\\nos.chdir('/content/drive/My Drive/Colab Notebooks/tcc')\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive/Colab Notebooks/tcc')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 208010,
     "status": "ok",
     "timestamp": 1589463057652,
     "user": {
      "displayName": "Moisés Oliveira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi3zXARzg3mEYgGoqoQsflEXnzm_wT1KuBZBsB37A=s64",
      "userId": "12199513049896561840"
     },
     "user_tz": 180
    },
    "id": "DME6l6elv6HA",
    "outputId": "5fac5898-3969-46a3-b881-27a195e264ce"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from modules.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2t9nI9pvMI8"
   },
   "outputs": [],
   "source": [
    "class EmotionDetect:\n",
    "    def __init__(self, vectors_name, w_folder):\n",
    "        self.w_folder = w_folder\n",
    "        self.size_word2vec = 300\n",
    "        self.max_sequences = 35\n",
    "        # self.vectors = pickle.load(open('w2v_stop'+str(self.size_word2vec)+'.pkl', 'rb'))\n",
    "        self.vectors = pickle.load(open(vectors_name, 'rb'))\n",
    "        self.emotions = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n",
    "        self.tokenizer = Tokenizer()\n",
    "        self.loadModels()\n",
    "\n",
    "    def model_gru(self, embedding_matrix, embed_size):\n",
    "        # load json and create model\n",
    "        json_file = open('models/bi-gru300.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        return tf.keras.models.model_from_json(loaded_model_json)\n",
    "\n",
    "    def loadModels(self):\n",
    "        self.models = dict()\n",
    "        for s in self.emotions:\n",
    "            self.models[s] = self.model_gru(self.vectors.wv.vectors, self.size_word2vec)\n",
    "            self.models[s].load_weights('models/'+s+ '_weights.h5')\n",
    "\n",
    "    def getIndex(self, t):\n",
    "        try:\n",
    "            return self.vectors.wv.vocab[t].index\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def predict(self, text):\n",
    "        x = self.tokenizer.cleanText(text)\n",
    "        x = [self.getIndex(t) for t in x]\n",
    "        x = tf.keras.preprocessing.sequence.pad_sequences([x], maxlen=self.max_sequences)\n",
    "        return dict(zip(self.emotions, [self.models[s].predict(x)[0][0] for s in self.emotions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bsm0Tyn536kd"
   },
   "outputs": [],
   "source": [
    "# classifier = EmotionDetect('models/ft_300.pkl', 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 264330,
     "status": "ok",
     "timestamp": 1589463114009,
     "user": {
      "displayName": "Moisés Oliveira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi3zXARzg3mEYgGoqoQsflEXnzm_wT1KuBZBsB37A=s64",
      "userId": "12199513049896561840"
     },
     "user_tz": 180
    },
    "id": "Dcixu0feflXy",
    "outputId": "208cc2fe-1e7f-454c-c27e-8e18c48410f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GetOldTweets3 in /opt/conda/lib/python3.7/site-packages (0.0.11)\n",
      "Requirement already satisfied: ratelimit in /opt/conda/lib/python3.7/site-packages (2.2.1)\n",
      "Requirement already satisfied: lxml>=3.5.0 in /opt/conda/lib/python3.7/site-packages (from GetOldTweets3) (4.4.2)\n",
      "Requirement already satisfied: pyquery>=1.2.10 in /opt/conda/lib/python3.7/site-packages (from GetOldTweets3) (1.4.1)\n",
      "Requirement already satisfied: cssselect>0.7.9 in /opt/conda/lib/python3.7/site-packages (from pyquery>=1.2.10->GetOldTweets3) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from random import randint\n",
    "from time import sleep\n",
    "\n",
    "!pip install GetOldTweets3 ratelimit\n",
    "import GetOldTweets3 as got\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "@sleep_and_retry\n",
    "@limits(calls=12, period=900) # 10 calls in 15 minutes\n",
    "def get_tweets_request(got, tweetCriteria):\n",
    "    try:\n",
    "        return got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "    except:\n",
    "        get_tweets_requst(got, tweetCriteria)\n",
    "\n",
    "def get_data(word, year=2020, month=1):\n",
    "\n",
    "    start_date = date(year, month, 1)\n",
    "    end_date = date(year, month, 1) + relativedelta(months=1)\n",
    "\n",
    "    tweets = []\n",
    "    for single_date in tqdm(daterange(start_date, end_date), total=(end_date - start_date).days):\n",
    "        # print(single_date)\n",
    "        day = single_date.strftime(\"%Y-%m-%d\")\n",
    "        dayPlus = (single_date + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        tweetCriteria = got.manager.TweetCriteria()\\\n",
    "                                            .setQuerySearch(word)\\\n",
    "                                            .setSince(day)\\\n",
    "                                            .setUntil(dayPlus)\\\n",
    "                                            .setLang('en')\\\n",
    "                                            .setTopTweets(True)\\\n",
    "                                            .setMaxTweets(1000)\n",
    "        tweet = get_tweets_request(got, tweetCriteria) # got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "        for t in (tweet):\n",
    "            # emo = classifier.predict(t.text)\n",
    "            tweets.append({\n",
    "                        'date': t.date,\n",
    "                        'id': t.id,\n",
    "                        'username': t.username,\n",
    "                        'text': t.text,\n",
    "                        'favorites': t.favorites,\n",
    "                        'retweets': t.retweets,\n",
    "                        'replies': t.replies,\n",
    "                        'geo': t.geo\n",
    "                        # 'anger' : int(emo['anger'] > 0.22),\n",
    "                        # 'disgust' : int(emo['disgust'] > 0.1),\n",
    "                        # 'fear': int(emo['fear'] > 0.1),\n",
    "                        # 'joy' : int(emo['joy'] > 0.1),\n",
    "                        # 'sadness' : int(emo['sadness'] > 0.1),\n",
    "                        # 'surprise': int(emo['surprise'] > 0.13),\n",
    "\n",
    "                        # 'anger_pred': emo['anger'],\n",
    "                        # 'disgust_pred' : emo['disgust'],\n",
    "                        # 'fear_pred': emo['fear'],\n",
    "                        # 'joy_pred': emo['joy'],\n",
    "                        # 'sadness_pred': emo['sadness'],\n",
    "                        # 'surprise_pred': emo['surprise']\n",
    "                        })\n",
    "        aux = pd.DataFrame(tweets)\n",
    "        aux.to_csv('data/data_autosave.csv')\n",
    "        sleep(randint(1,10))\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vH36ZZDbhl1n",
    "outputId": "7da24c43-db54-4914-fb4f-6b65e45f29df"
   },
   "outputs": [],
   "source": [
    "def get_plot(search, start_m=1, start_y=2019, end_m=1, end_y=2020):\n",
    "    for y, m in month_year_iter(start_m, start_y, end_m, end_y):\n",
    "        try:\n",
    "            name = str(y)+str(m)\n",
    "            tweets = get_data(search, year=y, month=m)\n",
    "            df = pd.DataFrame(tweets)\n",
    "            df.to_csv('data/tweets_'+search+'_'+name+'.csv')\n",
    "        except:\n",
    "            print('[ERROR]'+'data/tweets_'+search+'_'+name)\n",
    "            # continue\n",
    "        # df['date'] = pd.to_datetime(df['date']).dt.normalize()\n",
    "        # result = df.set_index('date')[['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']].resample(\"D\").sum()\n",
    "\n",
    "        # plot = result.plot(figsize=(20,10))\n",
    "        # plot.figure.savefig('figures/sent_'+search+'_'+name+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_plot('trump', 2, 2020, 3, 2020)\n",
    "# get_plot('trump', 5, 2020, 6, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_plot('coronavirus', 1, 2020, 4, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_plot('racism', 5, 2020, 6, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_plot('police', 7, 2019, 8, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot('police', 5, 2020, 6, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMD0+QOIYp8t98FcpUeVj9M",
   "collapsed_sections": [],
   "name": "3 - load_and_use",
   "provenance": []
  },
  "environment": {
   "name": "common-cpu.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
