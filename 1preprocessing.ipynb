{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "environment": {
      "name": "common-cpu.m46",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m46"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixkq-7lXzQ-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/tcc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-19T21:41:09.021283Z",
          "start_time": "2020-06-19T21:40:27.620247Z"
        },
        "colab_type": "code",
        "id": "yAwjm06epo1_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e7aa27aa-7835-46fd-d492-011990d84685"
      },
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from modules.preprocessing import *\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "prepare_text = Tokenizer()\n",
        "with open(\"dataset/unified-dataset.jsonl\", \"r\") as json_file:\n",
        "    json_list = list(json_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-19T21:47:47.344643Z",
          "start_time": "2020-06-19T21:47:47.327262Z"
        },
        "colab_type": "code",
        "id": "yQYg5fjmpo2H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "65b8d93b-488d-4956-b996-2c7ec9ff3e82"
      },
      "source": [
        "pprint(json.loads(json_list[12648]), indent=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'VAD': {'arousal': None, 'dominance': None, 'valence': None},\n",
            " 'annotation_procedure': 'crowdsourcing',\n",
            " 'domain': 'tweets',\n",
            " 'emotion_model': 'Ekman+CF',\n",
            " 'emotions': {'anger': 0,\n",
            "              'anticipation': None,\n",
            "              'confusion': None,\n",
            "              'disgust': 0,\n",
            "              'fear': 0,\n",
            "              'guilt': None,\n",
            "              'joy': 0,\n",
            "              'love': 0,\n",
            "              'noemo': 0,\n",
            "              'sadness': 1,\n",
            "              'shame': None,\n",
            "              'surprise': 0,\n",
            "              'trust': None},\n",
            " 'id': 12648,\n",
            " 'labeled': 'single',\n",
            " 'source': 'crowdflower',\n",
            " 'split': None,\n",
            " 'text': 'Layin n bed with a headache  ughhhh...waitin on your call...'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-19T16:49:06.030311Z",
          "start_time": "2020-06-19T15:28:43.616176Z"
        },
        "colab_type": "code",
        "id": "d9IAuMbPnKay",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "963a598f-a80d-49e2-b1c1-a044ab4934e9"
      },
      "source": [
        "datasets = {\n",
        "    \"text\": list(),\n",
        "    \"tokens\": list(),\n",
        "    \"source\": list(),\n",
        "    \"anger\": list(),\n",
        "    \"disgust\": list(),\n",
        "    \"fear\": list(),\n",
        "    \"joy\": list(),\n",
        "    \"love\": list(),\n",
        "    \"noemo\": list(),\n",
        "    \"sadness\": list(),\n",
        "    \"surprise\": list(),\n",
        "}\n",
        "\n",
        "\n",
        "for json_str in tqdm(json_list):\n",
        "    result = json.loads(json_str)\n",
        "    datasets[\"text\"].append(result[\"text\"])\n",
        "    datasets[\"tokens\"].append(prepare_text.cleanText(result[\"text\"]))\n",
        "    datasets[\"source\"].append(result[\"source\"])\n",
        "    datasets[\"anger\"].append(result[\"emotions\"][\"anger\"])\n",
        "    datasets[\"disgust\"].append(result[\"emotions\"][\"disgust\"])\n",
        "    datasets[\"fear\"].append(result[\"emotions\"][\"fear\"])\n",
        "    datasets[\"joy\"].append(result[\"emotions\"][\"joy\"])\n",
        "    datasets[\"love\"].append(result[\"emotions\"][\"love\"])\n",
        "    datasets[\"noemo\"].append(result[\"emotions\"][\"noemo\"])\n",
        "    datasets[\"sadness\"].append(result[\"emotions\"][\"sadness\"])\n",
        "    datasets[\"surprise\"].append(result[\"emotions\"][\"surprise\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 221439/221439 [40:01<00:00, 92.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-19T17:06:39.486Z"
        },
        "colab_type": "code",
        "id": "ibZojLwKZZEw",
        "colab": {}
      },
      "source": [
        "def save_object(obj, filename):\n",
        "    with open(filename, \"wb\") as output:  # Overwrites any existing file.\n",
        "        pickle.dump(datasets, output, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "save_object(datasets, \"dataset/organized_dataset.pkl\")\n",
        "\n",
        "# More metrics\n",
        "# https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "# https://nbviewer.jupyter.org/github/autonomio/talos/blob/master/examples/Hyperparameter%20Optimization%20with%20Keras%20for%20the%20Iris%20Prediction.ipynb#seven"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpY21ylAvFIo",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://miro.medium.com/max/1400/1*QbnbVSRoAyqLG76ZtF-oew.png\" style=\"width: 650px;\"/>\n",
        "<img src=\"https://www.researchgate.net/profile/Ruth_Campbell2/publication/279178495/figure/fig1/AS:614158332620800@1523438165009/Examples-of-the-Ekman-Friesen-Pictures-of-Facial-Affect-used-in-the-computerized-task.png\" style=\"width: 650px;\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8d5sH1fFpo2c"
      },
      "source": [
        "# Pré processamento\n",
        "\n",
        "## Tokenizer\n",
        "   É a forma que usamos para representar strings em pedaços menores também conhecidos como tokens. Geralmente cada token pode conter apenas uma palavra desde que esta carregue o significado completo, em casos nos quais são necessárias mais de uma palavra para representar o significado, mantemos as palavras juntas.\n",
        "\n",
        "```python\n",
        "phrase = \"city of new york\"\n",
        "tokens = tokenizer(phrase)\n",
        "# [\"city\", \"of\", \"new\", \"york\"] ou [\"city\", \"of\", \"new_york\"]\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "como é o caso do token \"New York\", que mantemos as duas palavras unidas visando não impactar no sentido final da sentença(bi-grams).\n",
        "\n",
        "## Stemmization\n",
        " \n",
        "  É o processo de converter uma palavra para sua forma básica agrupando diferentes formas de escrever, como por exemplo as palavras \"car, cars, car's, cars' são transformadas somente em \"car\", dessa forma facilitando a generalização do modelo treinado, pois ao abreviar diferentes variações da mesma palavra diminuindo o numero de vetores de palavras\n",
        "\n",
        "```python\n",
        "# [\"cars\", \"car\", \"am\", \"are\", \"is\", \"\"] -> [\"car\", \"car\", \"be\", \"york\",\"be\"]\n",
        "phrase = \"the boy's car are different colors\"\n",
        "tokens = tokenizer(phrase)\n",
        "stem(tokens)\n",
        "# [the boy car are different color\"]\n",
        "\n",
        "\n",
        "```\n"
      ]
    }
  ]
}