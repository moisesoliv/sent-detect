{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27581,
     "status": "ok",
     "timestamp": 1589462877201,
     "user": {
      "displayName": "Moisés Oliveira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi3zXARzg3mEYgGoqoQsflEXnzm_wT1KuBZBsB37A=s64",
      "userId": "12199513049896561840"
     },
     "user_tz": 180
    },
    "id": "veHVXrK3Yg8O",
    "outputId": "990cec7e-bc1e-4138-e260-b51a2f3cb705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive/Colab Notebooks/tcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 208010,
     "status": "ok",
     "timestamp": 1589463057652,
     "user": {
      "displayName": "Moisés Oliveira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi3zXARzg3mEYgGoqoQsflEXnzm_wT1KuBZBsB37A=s64",
      "userId": "12199513049896561840"
     },
     "user_tz": 180
    },
    "id": "DME6l6elv6HA",
    "outputId": "5fac5898-3969-46a3-b881-27a195e264ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2t9nI9pvMI8"
   },
   "outputs": [],
   "source": [
    "class EmotionDetect:\n",
    "    def __init__(self, vectors_name, w_folder):\n",
    "        self.w_folder = w_folder\n",
    "        self.size_word2vec = 300\n",
    "        self.max_sequences = 35\n",
    "        # self.vectors = pickle.load(open('w2v_stop'+str(self.size_word2vec)+'.pkl', 'rb'))\n",
    "        self.vectors = pickle.load(open('models/ft_'+str(self.size_word2vec)+'.pkl', 'rb'))\n",
    "        self.emotions = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n",
    "        self.tokenizer = Tokenizer()\n",
    "        self.loadModels()\n",
    "\n",
    "    def model_gru(self, embedding_matrix, embed_size):\n",
    "        # load json and create model\n",
    "        json_file = open('models/bi-gru300.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        return tf.keras.models.model_from_json(loaded_model_json)\n",
    "\n",
    "    def loadModels(self):\n",
    "        self.models = dict()\n",
    "        for s in self.emotions:\n",
    "            self.models[s] = self.model_gru(self.vectors.wv.vectors, self.size_word2vec)\n",
    "            self.models[s].load_weights('models/'+s+ '_weights.h5')\n",
    "    \n",
    "    def getIndex(self, t):\n",
    "        try:\n",
    "            return self.vectors.wv.vocab[t].index\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def predict(self, text):\n",
    "        x = self.tokenizer.cleanText(text)\n",
    "        x = [self.getIndex(t) for t in x]\n",
    "        x = tf.keras.preprocessing.sequence.pad_sequences([x], maxlen=self.max_sequences)\n",
    "        return dict(zip(self.emotions, [self.models[s].predict(x)[0][0] for s in self.emotions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bsm0Tyn536kd"
   },
   "outputs": [],
   "source": [
    "classifier = EmotionDetect('models/ft_300.pkl', 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 264330,
     "status": "ok",
     "timestamp": 1589463114009,
     "user": {
      "displayName": "Moisés Oliveira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi3zXARzg3mEYgGoqoQsflEXnzm_wT1KuBZBsB37A=s64",
      "userId": "12199513049896561840"
     },
     "user_tz": 180
    },
    "id": "Dcixu0feflXy",
    "outputId": "208cc2fe-1e7f-454c-c27e-8e18c48410f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GetOldTweets3\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/f4/a00c2a7c90801abc875325bb5416ce9090ac86d06a00cc887131bd73ba45/GetOldTweets3-0.0.11-py3-none-any.whl\n",
      "Collecting pyquery>=1.2.10\n",
      "  Downloading https://files.pythonhosted.org/packages/78/43/95d42e386c61cb639d1a0b94f0c0b9f0b7d6b981ad3c043a836c8b5bc68b/pyquery-1.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (4.2.6)\n",
      "Collecting cssselect>0.7.9\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
      "Installing collected packages: cssselect, pyquery, GetOldTweets3\n",
      "Successfully installed GetOldTweets3-0.0.11 cssselect-1.1.0 pyquery-1.4.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta, date\n",
    "!pip install GetOldTweets3\n",
    "import GetOldTweets3 as got\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "def get_data(word, year=2020, month=1):\n",
    "\n",
    "    start_date = date(year, month, 1)\n",
    "    end_date = date(year, month+1, 1)\n",
    "\n",
    "    tweets = []\n",
    "    for single_date in tqdm(daterange(start_date, end_date), total=(end_date - start_date).days):\n",
    "        # print(single_date)\n",
    "        day = single_date.strftime(\"%Y-%m-%d\")\n",
    "        dayPlus = (single_date + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        tweetCriteria = got.manager.TweetCriteria().setQuerySearch(word)\\\n",
    "                                            .setSince(day)\\\n",
    "                                            .setUntil(dayPlus)\\\n",
    "                                            .setLang('en')\\\n",
    "                                            .setTopTweets(True)\\\n",
    "                                            .setMaxTweets(1000)\n",
    "        tweet = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "        for t in (tweet):\n",
    "            emo = classifier.predict(t.text)\n",
    "            tweets.append({\n",
    "                        'date': t.date,\n",
    "                        'id': t.id,\n",
    "                        'text': t.text,\n",
    "                        'favorites': t.favorites,\n",
    "                        'retweets': t.retweets,\n",
    "                        'replies': t.replies,\n",
    "\n",
    "                        'anger' : int(emo['anger'] > 0.11),\n",
    "                        'disgust' : int(emo['disgust'] > 0.1),\n",
    "                        'fear': int(emo['fear'] > 0.1),\n",
    "                        'joy' : int(emo['joy'] > 0.1),\n",
    "                        'sadness' : int(emo['sadness'] > 0.1),\n",
    "                        'surprise': int(emo['surprise'] > 0.1),\n",
    "\n",
    "                        'anger_pred': emo['anger'],\n",
    "                        'disgust_pred' : emo['disgust'],\n",
    "                        'fear_pred': emo['fear'],\n",
    "                        'joy_pred': emo['joy'],\n",
    "                        'sadness_pred': emo['sadness'],\n",
    "                        'surprise_pred': emo['surprise']\n",
    "                        })\n",
    "        aux = pd.DataFrame(tweets)\n",
    "        aux.to_pickle('data/data_autosave.csv')\n",
    "    return tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vH36ZZDbhl1n",
    "outputId": "7da24c43-db54-4914-fb4f-6b65e45f29df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [37:38<1:29:09, 254.75s/it]"
     ]
    }
   ],
   "source": [
    "search = 'trump'\n",
    "for y, m in month_year_iter(9, 2019, 4, 2020):\n",
    "    name = str(y)+str(m)\n",
    "    tweets = get_data(search, year=y, month=m)\n",
    "    df = pd.DataFrame(tweets)\n",
    "    df.to_pickle('data/tweets_'+search+'_'+name+'.csv')\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.normalize()\n",
    "    result = df.set_index('date')[['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']].resample(\"D\").sum()\n",
    "    plot = result.plot.bar(stacked=True, figsize=(20,10))\n",
    "    plot.figure.savefig('figures/sent_'+search+'_'+name+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtIk6vYKH42h"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4Yin43Q4dtQ"
   },
   "outputs": [],
   "source": [
    "plot.figure.savefig('test.jpg')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMD0+QOIYp8t98FcpUeVj9M",
   "collapsed_sections": [],
   "name": "3 - load_and_use",
   "provenance": []
  },
  "environment": {
   "name": "common-cpu.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
