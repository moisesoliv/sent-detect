{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "veHVXrK3Yg8O",
    "outputId": "ced557b3-5305-4b67-db3e-d268b5739798"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n\\nimport os\\nos.chdir('/content/drive/My Drive/Colab Notebooks/tcc')\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive/Colab Notebooks/tcc')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DME6l6elv6HA"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from modules.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2t9nI9pvMI8"
   },
   "outputs": [],
   "source": [
    "class EmotionDetect:\n",
    "    def __init__(self, vectors_name, w_folder):\n",
    "        self.w_folder = w_folder\n",
    "        self.size_word2vec = 300\n",
    "        self.max_sequences = 35\n",
    "        # self.vectors = pickle.load(open('w2v_stop'+str(self.size_word2vec)+'.pkl', 'rb'))\n",
    "        self.vectors = pickle.load(open(vectors_name, 'rb'))\n",
    "        self.emotions = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n",
    "        self.tokenizer = Tokenizer()\n",
    "        self.loadModels()\n",
    "\n",
    "    def model_gru(self, embedding_matrix, embed_size):\n",
    "        # load json and create model\n",
    "        json_file = open('models/bi-gru300.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        return tf.keras.models.model_from_json(loaded_model_json)\n",
    "\n",
    "    def loadModels(self):   \n",
    "        self.models = dict()\n",
    "        for s in self.emotions:\n",
    "            self.models[s] = self.model_gru(self.vectors.wv.vectors, self.size_word2vec)\n",
    "            self.models[s].load_weights('models/'+s+ '_weights.h5')\n",
    "\n",
    "    def getIndex(self, t):\n",
    "        try:\n",
    "            return self.vectors.wv.vocab[t].index\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def predict(self, text):\n",
    "        x = self.tokenizer.cleanText(text)\n",
    "        x = [self.getIndex(t) for t in x]\n",
    "        x = tf.keras.preprocessing.sequence.pad_sequences([x], maxlen=self.max_sequences)\n",
    "        return dict(zip(self.emotions, [self.models[s].predict(x)[0][0] for s in self.emotions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bsm0Tyn536kd"
   },
   "outputs": [],
   "source": [
    "classifier = EmotionDetect('models/ft_300.pkl', 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DcGrFW11hrDV"
   },
   "outputs": [],
   "source": [
    "def predict_file(file):\n",
    "    try:\n",
    "        tweets = pd.read_csv(file)\n",
    "    except:\n",
    "        tweets = pd.read_pickle(file)\n",
    "\n",
    "    l = list()\n",
    "    for index, t in tweets.iterrows():\n",
    "        emo = classifier.predict(t.text)\n",
    "        l.append({\n",
    "                    'date': t['date'],\n",
    "                    'id': t['id'],\n",
    "                    'text': t['text'],\n",
    "                    'favorites': t['favorites'],\n",
    "                    'retweets': t['retweets'],\n",
    "                    'replies': t['replies'],\n",
    "                    'anger': int(emo['anger'] > 0.22),\n",
    "                    'disgust': int(emo['disgust'] > 0.1),\n",
    "                    'fear': int(emo['fear'] > 0.1),\n",
    "                    'joy': int(emo['joy'] > 0.1),\n",
    "                    'sadness': int(emo['sadness'] > 0.1),\n",
    "                    'surprise': int(emo['surprise'] > 0.13),\n",
    "                    'anger_pred': emo['anger'],\n",
    "                    'disgust_pred': emo['disgust'],\n",
    "                    'fear_pred': emo['fear'],\n",
    "                    'joy_pred': emo['joy'],\n",
    "                    'sadness_pred': emo['sadness'],\n",
    "                    'surprise_pred': emo['surprise']\n",
    "                    })\n",
    "\n",
    "    df = pd.DataFrame(l)\n",
    "    del l\n",
    "    df.to_csv('pred_'+file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m1YQg8QQTpqJ",
    "outputId": "f2131acc-e7a4-4996-b681-a65c388f5178"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/tweets_police_20205.csv\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "\n",
    "def find_csv_filenames(path_to_dir, suffix=\".csv\"):\n",
    "    filenames = listdir(path_to_dir)\n",
    "    return [filename for filename in filenames if filename.endswith(suffix)]\n",
    "\n",
    "filenames = find_csv_filenames(\"data\")\n",
    "done = find_csv_filenames(\"pred_data\")\n",
    "files = [l for l in filenames if l not in done]\n",
    "for name in tqdm(files):\n",
    "    if name not in done:\n",
    "        f = 'data/'+name\n",
    "        print(f)\n",
    "        try:\n",
    "            predict_file(f)\n",
    "        except:\n",
    "            print('ERRO: '+ f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3predict_data.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "common-cpu.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
