{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3predict_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "environment": {
      "name": "common-cpu.m46",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m46"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moisesoliv/sent-detect/blob/master/3predict_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyetTpmit0Pn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "dbaf5e1f-439e-4062-e2da-2d2de5f15f14"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/tcc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-19T15:27:04.568091Z",
          "start_time": "2020-06-19T15:27:02.561685Z"
        },
        "colab_type": "code",
        "id": "DME6l6elv6HA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "90424942-a849-42e7-8c45-22df4527d927"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "from modules.preprocessing import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-19T15:27:04.604641Z",
          "start_time": "2020-06-19T15:27:04.579008Z"
        },
        "colab_type": "code",
        "id": "n2t9nI9pvMI8",
        "colab": {}
      },
      "source": [
        "class EmotionDetect:\n",
        "    def __init__(self, vectors_name, w_folder):\n",
        "        self.w_folder = w_folder\n",
        "        self.size_word2vec = 300\n",
        "        self.max_sequences = 35\n",
        "        # self.vectors = pickle.load(open('w2v_stop'+str(self.size_word2vec)+'.pkl', 'rb'))\n",
        "        self.vectors = pickle.load(open(vectors_name, \"rb\"))\n",
        "        self.emotions = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
        "        self.tokenizer = Tokenizer()\n",
        "        self.loadModels()\n",
        "\n",
        "    def model_gru(self, embedding_matrix, embed_size):\n",
        "        # load json and create model\n",
        "        json_file = open(\"models/bi-gru300.json\", \"r\")\n",
        "        loaded_model_json = json_file.read()\n",
        "        json_file.close()\n",
        "        return tf.keras.models.model_from_json(loaded_model_json)\n",
        "\n",
        "    def loadModels(self):\n",
        "        self.models = dict()\n",
        "        for s in self.emotions:\n",
        "            self.models[s] = self.model_gru(self.vectors.wv.vectors, self.size_word2vec)\n",
        "            self.models[s].load_weights(\"models/\" + s + \"_weights.h5\")\n",
        "\n",
        "    def getIndex(self, t):\n",
        "        try:\n",
        "            return self.vectors.wv.vocab[t].index\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "    def predict(self, text):\n",
        "        x = self.tokenizer.cleanText(text)\n",
        "        x = [self.getIndex(t) for t in x]\n",
        "        x = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "            [x], maxlen=self.max_sequences\n",
        "        )\n",
        "        return dict(\n",
        "            zip(self.emotions, [self.models[s].predict(x)[0][0] for s in self.emotions])\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-19T15:27:13.999673Z",
          "start_time": "2020-06-19T15:27:04.607908Z"
        },
        "colab_type": "code",
        "id": "Bsm0Tyn536kd",
        "colab": {}
      },
      "source": [
        "classifier = EmotionDetect(\"models/ft_300.pkl\", \"models\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-19T21:31:24.075Z"
        },
        "id": "AryeFs0NK762",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8a0eb35e-aebd-401d-8858-63d9fd29fab2"
      },
      "source": [
        "classifier.predict(\"hello world!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'anger': 1.758303e-17,\n",
              " 'disgust': 1.2089988e-15,\n",
              " 'fear': 8.738927e-19,\n",
              " 'joy': 0.09627417,\n",
              " 'sadness': 2.6074428e-23,\n",
              " 'surprise': 7.228096e-06}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-19T15:27:14.018033Z",
          "start_time": "2020-06-19T15:27:14.003123Z"
        },
        "colab_type": "code",
        "id": "DcGrFW11hrDV",
        "colab": {}
      },
      "source": [
        "def predict_file(file):\n",
        "    try:\n",
        "        tweets = pd.read_csv(file)\n",
        "    except:\n",
        "        tweets = pd.read_pickle(file)\n",
        "\n",
        "    l = list()\n",
        "    for index, t in tweets.iterrows():\n",
        "        emo = classifier.predict(t.text)\n",
        "        l.append(\n",
        "            {\n",
        "                \"date\": t[\"date\"],\n",
        "                \"id\": t[\"id\"],\n",
        "                \"text\": t[\"text\"],\n",
        "                \"favorites\": t[\"favorites\"],\n",
        "                \"retweets\": t[\"retweets\"],\n",
        "                \"replies\": t[\"replies\"],\n",
        "\n",
        "                \"anger\": int(emo[\"anger\"] > 0.12),\n",
        "                \"disgust\": int(emo[\"disgust\"] > 0.44),\n",
        "                \"fear\": int(emo[\"fear\"] > 0.1),\n",
        "                \"joy\": int(emo[\"joy\"] > 0.1),\n",
        "                \"sadness\": int(emo[\"sadness\"] > 0.11),\n",
        "                \"surprise\": int(emo[\"surprise\"] > 0.13),\n",
        "\n",
        "                \"anger_pred\": emo[\"anger\"],\n",
        "                \"disgust_pred\": emo[\"disgust\"],\n",
        "                \"fear_pred\": emo[\"fear\"],\n",
        "                \"joy_pred\": emo[\"joy\"],\n",
        "                \"sadness_pred\": emo[\"sadness\"],\n",
        "                \"surprise_pred\": emo[\"surprise\"],\n",
        "            }\n",
        "        )\n",
        "\n",
        "    df = pd.DataFrame(l)\n",
        "    del l\n",
        "    df.to_csv(\"pred_\" + file)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-06-19T15:27:02.569Z"
        },
        "colab_type": "code",
        "id": "m1YQg8QQTpqJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf3c4484-974e-4dae-ffed-1ed9c082611d"
      },
      "source": [
        "from os import listdir\n",
        "\n",
        "def find_csv_filenames(path_to_dir, suffix=\".csv\"):\n",
        "    filenames = listdir(path_to_dir)\n",
        "    return [filename for filename in filenames if filename.endswith(suffix)]\n",
        "\n",
        "\n",
        "filenames = find_csv_filenames(\"data\")\n",
        "done = find_csv_filenames(\"pred_data\")\n",
        "files = [l for l in filenames if l not in done]\n",
        "for name in tqdm(files):\n",
        "    if name not in done:\n",
        "        f = \"data/\" + name\n",
        "        print(f)\n",
        "        try:\n",
        "            predict_file(f)\n",
        "        except:\n",
        "            print(\"ERRO: \" + f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}